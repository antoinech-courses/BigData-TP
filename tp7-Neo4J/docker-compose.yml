services:
  spark:
    image: docker.io/bitnami/spark:3.5
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    ports:
      - '8080:8080'
      - '7077:7077'
      - '18888:8888'
  spark-worker:
    image: docker.io/bitnami/spark:3.5
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G # can be changed
      - SPARK_WORKER_CORES=1 # can be changed
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    ports:
      - '8081:8081'
    volumes:
      - ./graphframes_cps:/opt/bitnami/spark/work/graphframes_cps
  minio:
    image: minio/minio
    container_name: miniobis
    environment:
      MINIO_ROOT_USER: root
      MINIO_ROOT_PASSWORD: password
    command: server /data --console-address ":9001"
    ports:
      - "19000:9000"
      - "19001:9001"
  zookeeper1:
    image: bitnami/zookeeper:latest
    environment:
      ALLOW_ANONYMOUS_LOGIN: "yes"
  kafka1:
    image: bitnami/kafka:3.0.2
    depends_on:
      - zookeeper1
    environment: # https://rmoff.net/2018/08/02/kafka-listeners-explained/
      KAFKA_BROKER_ID: 1
      KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper1:2181
      #KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: INTERNAL://:9092,PROXY://0.0.0.0:9093,OUTSIDE://0.0.0.0:9095,PROXY_PASSTHROUGH://0.0.0.0:9096
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://:9092,PROXY://envoy1:9093,OUTSIDE://localhost:9095,PROXY_PASSTHROUGH://envoy1:9096
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,PROXY:PLAINTEXT,OUTSIDE:PLAINTEXT,PROXY_PASSTHROUGH:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      ALLOW_PLAINTEXT_LISTENER: "yes"
      KAFKA_NUM_PARTITIONS: ${NUM_PARTITIONS:-2}
  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    ports:
      - "8082:8080"
    restart: always
    environment:
      - KAFKA_CLUSTERS_0_NAME=kafka1
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka1:9092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper1:2181

  neo4j:
    image: neo4j:5.25.1
    #restart: always
    container_name: neo4j
    volumes:
      - neodata:/var/lib/neo4j/data
      - neoimport:/var/lib/neo4j/import
      - neoplugins:/var/lib/neo4j/plugins
    ports:
      - "0.0.0.0:7474:7474"
      - "0.0.0.0:7687:7687"
    environment:
      NEO4J_dbms_security_procedures_unrestricted: "example.*, apoc.*"
      NEO4J_dbms_security_procedures_allowlist: "example.*, apoc.*"
      NEO4J_dbms_memory_pagecache_size: "200M"
      NEO4J_dbms_memory_heap_initial__size: "512M"
      NEO4J_dbms_memory_heap_max__size: "512M"
      NEO4J_AUTH: neo4j/neo4jtp9
      NEO4J_dbms_security_auth__minimum__password__length: 7
      NEO4J_PLUGINS: \[\"apoc\", \"graph-data-science\"]\
      NEO4J_apoc_export_file_enabled: true
      NEO4J_apoc_import_file_enabled: true
      NEO4J_apoc_import_file_use__neo4j__config: true

volumes:
  neodata:
  neoimport:
  neoplugins:


networks:
  default:
    name : tp9